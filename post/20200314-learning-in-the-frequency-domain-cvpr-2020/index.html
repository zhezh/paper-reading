<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Learning in the Frequency Domain (CVPR 2020) - Paper Reading</title>
<link rel="shortcut icon" href="https://www.zhe-zhang.com/paper-reading/favicon.ico">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@latest/media/css/tailwind.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@latest/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Learning in the Frequency Domain (CVPR 2020) - Paper Reading - Atom Feed" href="https://www.zhe-zhang.com/paper-reading/atom.xml">


  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160677444-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-160677444-1');
  </script>
    

  <meta name="description" content="Highlight
通过压缩神经网络的输入, 增大输入图片的尺寸, 从而提升视觉任务的性能.

文章链接: arXiv
代码链接: GitHub
作者信息:

Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang..." />
  <meta property="og:title" content="Learning in the Frequency Domain (CVPR 2020) - Paper Reading">
  <meta property="og:description" content="Highlight
通过压缩神经网络的输入, 增大输入图片的尺寸, 从而提升视觉任务的性能.

文章链接: arXiv
代码链接: GitHub
作者信息:

Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang..." />
  <meta property="og:type" content="articles">
  <meta property="og:url" content="https://www.zhe-zhang.com/paper-reading/post/20200314-learning-in-the-frequency-domain-cvpr-2020/" />
  <meta property="og:image" content="https://www.zhe-zhang.com/paper-reading/post-images/20200314-learning-in-the-frequency-domain-cvpr-2020.png">
  <meta property="og:image:height" content="630">
  <meta property="og:image:width" content="1200">
  <meta name="twitter:title" content="Learning in the Frequency Domain (CVPR 2020) - Paper Reading">
  <meta name="twitter:description" content="Highlight
通过压缩神经网络的输入, 增大输入图片的尺寸, 从而提升视觉任务的性能.

文章链接: arXiv
代码链接: GitHub
作者信息:

Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang...">
  <meta name="twitter:card" content="summary_large_image">
  <link rel="canonical" href="https://www.zhe-zhang.com/paper-reading/post/20200314-learning-in-the-frequency-domain-cvpr-2020/">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
 
  
    <link rel="stylesheet" href="https://www.zhe-zhang.com/paper-reading/media/css/prism-atom-dark.css">
  

  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
  
</head>

<body>
  <div class="antialiased flex flex-col min-h-screen" id="app">
    <a href="https://www.zhe-zhang.com/paper-reading" class="fixed top-0 left-0 mt-4 bg-black text-white dark:text-gray-700 dark:bg-yellow-50 dark:hover:bg-black dark:hover:text-white inline-flex p-2 pl-8 hover:text-gray-700 hover:bg-yellow-50 font-bold z-10 transition-fast animated fadeInLeft">
      Paper Reading
    </a>
    <div class="max-w-4xl w-full mx-auto">
      <div class="shadow-box bg-white dark:bg-gray-600 rounded-lg pt-32 md:pt-64 px-4 md:px-8 pb-8 animated fadeIn mb-8">
        <h1 class="text-5xl font-semibold leading-normal pb-8 mb-8 border-b-8 border-gray-700">
          Learning in the Frequency Domain (CVPR 2020)
        </h1>
        
          <img src="https://www.zhe-zhang.com/paper-reading/post-images/20200314-learning-in-the-frequency-domain-cvpr-2020.png" alt="Learning in the Frequency Domain (CVPR 2020)" class="block w-full mb-8">
        
        <div class="mb-8 flex flex-wrap">
          <div class="text-gray-400 text-sm mr-4">2020-03-14 · 5 min read</div>
          
            <a href="https://www.zhe-zhang.com/paper-reading/tag/Rjl6mfECN/" class="text-gray-700 text-sm border-b-2 border-dotted border-gray-200 hover:border-gray-600 transition-all duration-100 inline-flex mr-2">
              <i class="ri-hashtag"></i>
              CVPR
            </a>
          
            <a href="https://www.zhe-zhang.com/paper-reading/tag/P4TdqnleKs/" class="text-gray-700 text-sm border-b-2 border-dotted border-gray-200 hover:border-gray-600 transition-all duration-100 inline-flex mr-2">
              <i class="ri-hashtag"></i>
              2020
            </a>
          
            <a href="https://www.zhe-zhang.com/paper-reading/tag/vv3yI80XPC/" class="text-gray-700 text-sm border-b-2 border-dotted border-gray-200 hover:border-gray-600 transition-all duration-100 inline-flex mr-2">
              <i class="ri-hashtag"></i>
              DCT
            </a>
          
        </div>
        <div class="markdown mb-8" v-pre>
		    <p><strong>Highlight</strong><br>
通过压缩神经网络的输入, 增大输入图片的尺寸, 从而提升视觉任务的性能.</p>
<!-- more -->
<p>文章链接: <a href="https://arxiv.org/abs/2002.12416">arXiv</a><br>
代码链接: <a href="https://github.com/calmevtime/DCTNet">GitHub</a><br>
作者信息:</p>
<blockquote>
<p>Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, Fengbo Ren<br>
DAMO Academy, Alibaba Group<br>
Arizona State University</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>由于GPU设备Memory的限制, 当前视觉任务模型中, 输入图像的尺寸较小. 这限制了模型性能, 本文提出了一种通过图像压缩的方法, 来增大深度神经网络实际的输入图像尺寸的方法. 具体实现是在频率域上对图像进行频域变换, 然后将图像的频域特征输入给神经网络. 然后使用了一种结合了重参数化方法的SE block的模块自适应地学习哪些频率对于特定的视觉任务比较有效. 最后, 基于在数据集层面的统计特征, 选出最有效的 N个频率, 丢掉其余频率的数据, 实现对输入数据的压缩, 并且不会有性能损失. 文章展示并验证了通过压缩的方法将输入图像的尺寸变大, 从而实现最终性能提升的思路.</p>
<h2 id="method">Method</h2>
<h3 id="data-pre-processing-in-the-frequency-domain">Data Pre-processing in the Frequency Domain</h3>
<p><img src="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@masterpost-images/1584167531663.png" alt="PreparingInput" loading="lazy"><br>
图像输入到神经网络前的预处理步骤如图所示, 主要包括:</p>
<ul>
<li>从原图中裁剪出或将原图调整为固定输入尺寸的图像</li>
<li>将图像由RGB色域转换到YCbCr色域, 本质上是线性变换</li>
<li>将Y, Cb, Cr通道分别通过DCT变换到频率域, 本文使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span>的核, 与JPEG压缩使用的是相同大小的核, 相当于过了层 channel数为 64 的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span> / stride 8 的卷积. 经过DCT后边长变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, 通道数变为 64x.</li>
<li>通过动态或静态的方式选取若干通道, 拼接成一个新的tensor. 这里注意下图中 Y 通道选取了2个channel, Cb和Cr通道都只留了1个channel, 不是图画错了, 而是通道选择在3路中是独立的, 最终实验结果Y通道留下的channel更多</li>
<li>最后, 基于预计算的整个数据集统计的均值和方差去normalize每一张图</li>
</ul>
<h3 id="learning-based-frequency-channel-selection">Learning-based Frequency Channel Selection</h3>
<p><img src="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@masterpost-images/1584168809346.png" alt="" width="400" height="1" loading="lazy"><br>
由于selection这个操作不可微, 这里使用了Gumbel Trick对selection的操作进行重参数化, 使得操作变得可微分. 该操作在NAS等领域已有很多应用, 这里就不详细说了.<br>
需要注意的是由<code>Tensor 3</code>变为<code>Tensor 4</code>的时候, 乘以了两个可学习的参数, 来确定某一个channel保留的概率, 经过与作者确认, 这里使用一个参数也是可以实现的.<br>
最后, loss中也加入了channel selection 的约束, 鼓励网络丢掉channel, 避免出现大量全都保留的情况.</p>
<h3 id="static-frequency-channel-selection">Static Frequency Channel Selection</h3>
<p><img src="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@masterpost-images/1584169150720.png" alt="" width="500" height="1" loading="lazy"><br>
在输入是full channel的情况下, 训练得到模型, 然后在整个数据集上统计得到所有channel保留的概率, 得到以上的Heatmap. 可以发现:</p>
<ul>
<li>保留的channel基本都是低频的</li>
<li>亮度通道Y保留的比浓度通道要多</li>
<li>对于不同的视觉任务, 保留的通道的特征差不多(上下两行差不多)</li>
</ul>
<h2 id="experiment-results">Experiment Results</h2>
<p><img src="https://cdn.jsdelivr.net/gh/zhezh/paper-reading@masterpost-images/1584169474438.png" alt="" loading="lazy"><br>
对比1,3行, 当输入是<code>DCT-192</code>时, Top-1提升了约 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0.3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">0.3\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">%</span></span></span></span>, 文中没有对此的分析, 我个人猜测是因为DCT作为一种手工设计的特征, 在这个任务中取得了比学习的方法的更好的效果. 理论上来说, 自深度网络开始流行以来, 大家都认为我们不要手工设计特征, 要让网络自动学习特征, 但网络不一定在所有情况下都能学到更好的特征. 本文这个实验结果也许就是因为引入了DCT这种具有inductive bias的特征得到的gain.<br>
其他的结果, 文中分析得也比较清晰了, <code>DCT-24</code>和<code>DCT-48</code>也能得到和<code>DCT-192</code>差不多的结果, 对比通道选择的Heatmap数一数也可以知道, 如果通道低于24, 性能就要开始明显下降了.</p>
<h2 id="comments">Comments</h2>
<p>可能有的人看完文章会觉得文中与Baseline方法的对比不够公平. 应该将Baseline的输入也扩大到4x面积, 然后接一层Conv, 再通过selection的方法丢掉一些通道. 不过这就不是本文的setting了. 本文claim的就是要输入更大的图, 通过压缩, 使得网络能够handle大的图. DCT只是一种手段, 刚刚提到的也许是另一种可行的手段. 本文不是要去说DCT比学习的特征更好, 不过如果能做一下这个分析可能会更完善.</p>
			

        </div>
        <!-- Share to Twitter, Weibo, Telegram -->
        <div class="flex items-center">
          <div class="mr-4 flex items-center">
            <i class="ri-share-forward-line text-gray-500"></i>
          </div>
          <div class="px-4 cursor-pointer text-blue-500 hover:bg-blue-100 dark:hover:bg-gray-600 inline-flex" @click="shareToTwitter">
            <i class="ri-twitter-line"></i>
          </div>
          <div class="px-4 cursor-pointer text-red-500 hover:bg-red-100 dark:hover:bg-gray-600 inline-flex" @click="shareToWeibo">
            <i class="ri-weibo-line"></i>
          </div>
          <div class="px-4 cursor-pointer text-indigo-500 hover:bg-indigo-100 dark:hover:bg-gray-600 inline-flex" @click="shareToTelegram">
            <i class="ri-telegram-line"></i>
          </div>
        </div>
      </div>

      
        
          <div id="gitalk-container"></div>
        

        
      

      

      <footer class="py-12 text-center px-4 md:px-0" v-pre>
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
</footer>
    </div>

    <!-- TOC Container -->
    <div class="fixed right-0 bottom-0 mb-16 mr-4 shadow w-8 h-8 rounded-full flex justify-center items-center z-10 cursor-pointer bg-white dark:bg-gray-500 dark:text-gray-200 hover:shadow-lg transition-all animated fadeInRight" @click="showToc = true">
      <i class="ri-file-list-line"></i>
    </div>

    <div class="fixed right-0 top-0 bottom-0 overflow-y-auto w-64 bg-white dark:bg-gray-800 p-4 border-l border-gray-100 dark:border-gray-600 z-10 transition-fast" :class="{ '-mr-64': !showToc }">
      <div class="flex mb-4 justify-end">
        <div class="w-8 h-8 inline-flex justify-center items-center rounded-full cursor-pointer hover:bg-gray-200 dark:hover:bg-gray-600 transition-fast" @click="showToc = false">
          <i class="ri-close-line text-lg"></i>
        </div>
      </div>
      <div class="post-toc-container">
        <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#method">Method</a>
<ul>
<li><a href="#data-pre-processing-in-the-frequency-domain">Data Pre-processing in the Frequency Domain</a></li>
<li><a href="#learning-based-frequency-channel-selection">Learning-based Frequency Channel Selection</a></li>
<li><a href="#static-frequency-channel-selection">Static Frequency Channel Selection</a></li>
</ul>
</li>
<li><a href="#experiment-results">Experiment Results</a></li>
<li><a href="#comments">Comments</a></li>
</ul>
</li>
</ul>

      </div>
    </div>

    <!-- Back to top -->
    <div class="fixed right-0 bottom-0 mb-4 mr-4 shadow w-8 h-8 rounded-full flex justify-center items-center z-10 cursor-pointer bg-white hover:shadow-lg transition-all dark:bg-gray-500 dark:text-gray-200" @click="backToUp" v-show="scrolled">
      <i class="ri-arrow-up-line"></i>
    </div>
  </div>

  <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
  <!-- Background of PhotoSwipe. 
        It's a separate element as animating opacity is faster than rgba(). -->
  <div class="pswp__bg">
  </div>
  <!-- Slides wrapper with overflow:hidden. -->
  <div class="pswp__scroll-wrap">
    <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
    <div class="pswp__container">
      <div class="pswp__item">
      </div>
      <div class="pswp__item">
      </div>
      <div class="pswp__item">
      </div>
    </div>
    <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
    <div class="pswp__ui pswp__ui--hidden">
      <div class="pswp__top-bar">
        <!--  Controls are self-explanatory. Order can be changed. -->
        <div class="pswp__counter">
        </div>
        <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
        <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
        <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
        <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
        <!-- element will get class pswp__preloader--active when preloader is running -->
        <div class="pswp__preloader">
          <div class="pswp__preloader__icn">
            <div class="pswp__preloader__cut">
              <div class="pswp__preloader__donut">
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
        <div class="pswp__share-tooltip">
        </div>
      </div>
      <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
      </button>
      <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
      </button>
      <div class="pswp__caption">
        <div class="pswp__caption__center">
        </div>
      </div>
    </div>
  </div>
</div>

  <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
  <script src="https://www.zhe-zhang.com/paper-reading/media/scripts/main.js"></script>
  
  <!-- Code Highlight -->
  
    <script src="https://www.zhe-zhang.com/paper-reading/media/prism.js"></script>
    <script>
      Prism.highlightAll()
    </script>
  

  <script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>
  <script>
    //拿到预览框架，也就是上面的html代码
    var pswpElement = document.querySelectorAll('.pswp')[0];
    //定义图片数组变量
    var imgitems;
    /**
    * 用于显示预览界面
    * @param index 图片数组下标
    */
    function viewImg(index) {
      //其它选项这里不做过多阐述，详情见官网
      var pswpoptions = {
        index: parseInt(index, 10), // 开始幻灯片索引。0是第一张幻灯片。必须是整数，而不是字符串。
        bgOpacity: 0.7, // 背景透明度，0-1
        maxSpreadZoom: 3, // 缩放级别，不要太大
      };
      //初始化并打开PhotoSwipe，pswpElement对应上面预览框架，PhotoSwipeUI_Default为皮肤，imgitems为图片数组，pswpoptions为选项
      var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, imgitems, pswpoptions);
      gallery.init()
    }
    /**
    * 用于添加图片点击事件
    * @param img 图片元素
    * @param index 所属下标（在imgitems中的位置）
    */
    function addImgClick(img, index) {
      img.onclick = function() {
        viewImg(index)
      }
    }
    /**
    * 轮询所有图片，获取src、width、height等数据，加入imgitems，并给图片元素添加事件
    * 最好在onload中执行该方法，本站因放在最底部，所以直接初始化
    * 异步加载图片可在图片元素创建完成后调用此方法
    */
    function initImg() {
      //重置图片数组
      imgitems = [];
      //查找class:markdown 下的所有img元素并遍历
      var imgs = document.querySelectorAll('.markdown img');
      for (var i = 0; i < imgs.length; i++) {
        var img = imgs[i];
        //本站相册初始为loading图片，真实图片放在data-src
        var ds = img.getAttribute("data-src");
        //创建image对象，用于获取图片宽高
        var imgtemp = new Image();
        //判断是否存在data-src
        if (ds != null && ds.length > 0) {
          imgtemp.src = ds
        } else {
          imgtemp.src = img.src
        }
        //判断是否存在缓存
        if (imgtemp.complete) {
          var imgobj = {
            "src": imgtemp.src,
            "w": imgtemp.width,
            "h": imgtemp.height,
          };
          imgitems[i] = imgobj;
          addImgClick(img, i);
        } else {
          console.log('进来了2')
          imgtemp.index = i;
          imgtemp.img = img;
          imgtemp.onload = function() {
            var imgobj = {
              "src": this.src,
              "w": this.width,
              "h": this.height,
            };
            //不要使用push，因为onload前后顺序会不同
            imgitems[this.index] = imgobj
            //添加点击事件
            addImgClick(this.img, this.index);
          }
        }
      }
    }
    //初始化
    initImg();
  </script>
  
  
    
      <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script type="application/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="application/javascript">

  var gitalk = new Gitalk({
    clientID: 'c25e8fc7dc8c8bac9eb9',
    clientSecret: 'b0762e65fb60c26f993861805818b29d5888802f',
    repo: 'paper-reading',
    owner: 'zhezh',
    admin: ['zhezh'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

    
  
</body>

</html>